<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>New article on historical color photography and multimodal ML published in Visual Studies | Thomas Smits</title> <meta name="author" content="Thomas Smits"> <meta name="description" content="Thomas Smits website &gt; "> <meta name="keywords" content="(visual) history, visual (news) culture, machine learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%B7&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tpsmi.github.io/news/announcement_12/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Thomas </span>Smits</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">New article on historical color photography and multimodal ML published in Visual Studies</h1> <p class="post-meta">August 25, 2024</p> <p class="post-tags"> <a href="/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>I’m happy to announce that my new article - ‘Revisiting the Kahn collection: multimodal artificial intelligence and visual patterns of presence and absence in the Archives de la Planète, 1909–1931’ - was published in Visual Studies.</p> <p>Please read the <a href="https://www.tandfonline.com/doi/full/10.1080/1472586X.2024.2380859" rel="external nofollow noopener" target="_blank">abstract (or the article of course)</a> for more information. I’ve included some of the figures of the article, which highlight the most important conclusions.</p> <p><strong>Abstract</strong> Financed by the French banker Albert Kahn, the Archives of the Planet is one of the most important collections of early photography. Produced between 1909 and 1931, its 72,000 autochromes show a world we are accustomed to seeing in black and white, captured in colour. While Kahn focused on volume, scholars have mostly studied the collection by close reading a small number of pictures. In contrast, this article applies a distant viewing methodology – a combination of data analysis and multimodal AI – to examine, compare, and analyse all the thousands of pictures in the Archives of the Planet. Using spatial metadata, it reveals that the world represented by the collection is significantly smaller than previously assumed: only 22 countries appear more than 100 times in the archive. Applying multimodal AI reveals that a large proportion of the archive (∼25%) consists of the same or extremely similar images. Challenging previous claims about the collection’s heterogeneity, algorithmic clustering of the images demonstrates that Kahn’s photographers captured similar scenes, adhering closely to the scientific principles of the project. On a general level, the article demonstrates that a distant viewing methodology can help find patterns of presence as well as patterns of absence: the silent parts of the archive.</p> <p>In the <strong>first part of the article</strong>, I use spatial metadata to examine where the 72,000 autochromes were taken. I argue that this helps us understand which “world” the Kahn collection shows: what parts of the globe become visible and which parts stay hidden.</p> <p>Figure 3 plots the autochromes of the collection on a map of France. The line in the north of France highlights the importance of several photographic missions that were meant to capture the destruction of the First World War. We might argue that these thousands of pictures do not adhere to the overall goals of the project.</p> <div class="container text-center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <div class="d-flex justify-content-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kahnfrance-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kahnfrance-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kahnfrance-1400.webp"></source> <img src="/assets/img/kahnfrance.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </div> <div class="caption mt-3"> Table </div> </div> <p>Figure 4 plots the autochromes of the collection on a map of the world. The article describes how this visualization highlights the survivorship bias of historical collections: we often solely base our findings on surviving data and ignore the silent parts of the historical archive.</p> <div class="container text-center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <div class="d-flex justify-content-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kahnworld-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kahnworld-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kahnworld-1400.webp"></source> <img src="/assets/img/kahnworld.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </div> <div class="caption mt-3"> Table </div> </div> <p>The second part of the article shows how we can use multimodal machine learning to cluster the autochromes based on visual similarity. Each point in Figure 6 represents an individual photograph, and these are color-coded into twelve distinct clusters as indicated by the legend.</p> <div class="container text-center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <div class="d-flex justify-content-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kahnkmeans-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kahnkmeans-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kahnkmeans-1400.webp"></source> <img src="/assets/img/kahnkmeans.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </div> <div class="caption mt-3"> Table </div> </div> <p>Figure 7 displays the 6 autochromes nearest to the 12 cluster centroids: the mean (average) position of all the pictures in a specific cluster. As mentioned in the methodology, the clusters are mathematically coherent, which does not necessarily mean that they reveal relevant or meaningful visual patterns for humans. However, inspecting the 12 clusters makes clear that all of them display a form of visual coherence. Based on the images in Figure 7, we can describe the 12 clusters as being focused on: Western cities, Mountains and hills, Ruins, Persons, Japanese built environment, Towns, Empty plains, Desert built environment, Architectural details (inside), Plains built environment, Hills and rivers built environment, and Trees and vegetation.</p> <div class="container text-center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <div class="d-flex justify-content-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kahnclusters-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kahnclusters-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kahnclusters-1400.webp"></source> <img src="/assets/img/kahnclusters.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </div> <div class="caption mt-3"> Table </div> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Thomas Smits. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. . </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>